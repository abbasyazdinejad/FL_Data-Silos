import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt
from copy import deepcopy

scenarios = [
    "Centralized AI",
    "Federated (No Privacy)",
    "Federated + DP (Œµ ‚âà 3.0)",
    "Federated + DP (Œµ ‚âà 1.5)",
    "Federated + DP (Œµ ‚âà 1.0)",
]

data = {
    "Scenario": scenarios,
    "Accuracy (%)": [95.9, 94.2, 92.5, 91.8, 91.3],
    "Macro-F1 (%)": [94.1, 92.6, 91.4, 91.2, 91.1],
    "Estimated Œµ": [np.inf, np.inf, 3.0, 1.5, 1.0]
}

df = pd.DataFrame(data)


df["Accuracy (%)"] = df["Accuracy (%)"].map(lambda x: f"{x:.1f}")
df["Macro-F1 (%)"] = df["Macro-F1 (%)"].map(lambda x: f"{x:.1f}")
df["Estimated Œµ"] = df["Estimated Œµ"].map(lambda x: f"{x}" if x != np.inf else "‚àû")


print("Simulated FL + Privacy Performance Summary")
print(df.to_markdown(index=False))

# Differential Privacy Noise Function
def apply_dp(model, noise_scale=1e-3):
    for param in model.parameters():
        if param.grad is not None:
            noise = torch.normal(0, noise_scale, size=param.grad.shape).to(param.device)
            param.grad += noise

# Local Training with DP
def local_train_dp(model, dataloader, epochs=1, lr=0.001, dp=True, noise_scale=1e-3):
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    for _ in range(epochs):
        for x, y in dataloader:
            x, y = x.to(device), y.squeeze().to(device)
            optimizer.zero_grad()
            preds = model(x)
            loss = criterion(preds, y)
            loss.backward()
            if dp:
                apply_dp(model, noise_scale=noise_scale)
            optimizer.step()

#  Model Weight Utilities
def get_model_weights(model):
    return {k: v.cpu().clone() for k, v in model.state_dict().items()}


# Federated Training Loop with Visualization
round_accuracies = []
global_model = CNN().to(device)

for rnd in range(5):
    print(f"\nüîêüåê Federated Round {rnd+1} | üîè Differential Privacy Enabled")

    local_weights = []

    for i in range(5):
        local_model = deepcopy(global_model)
        local_loader = DataLoader(hospital_datasets[i], batch_size=64, shuffle=True)
        local_train_dp(local_model, local_loader, epochs=1)
        local_weights.append(get_model_weights(local_model))

    avg_weights = average_weights(local_weights)
    set_model_weights(global_model, avg_weights)

    acc = evaluate_model(global_model, test_loader)
    round_accuracies.append(acc)
    print(f" Global Accuracy after Round {rnd+1}: {acc:.4f}  Secure |  Auditable")