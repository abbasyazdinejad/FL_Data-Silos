# How Federated Learning Can Unlock Canadaâ€™s Public Health Potential

This repository contains the code, datasets, and experimental workflows supporting **privacy-preserving and governance-aware federated learning** for Canadian healthcare applications.

## ğŸ“‚ Contents

- `notebooks/` â€“ Jupyter notebooks for:
  - Generating **synthetic non-IID cancer data** across provinces (Ontario, Alberta, Quebec)
  - **Federated training** on PathMNIST for cancer tissue classification
- `data/` â€“ CSV datasets for three provinces + combined dataset
- `DP.py` â€“ Implements differential privacy (DP-SGD) and performanceâ€“privacy trade-off analysis
- `equity_bias_simulation.py` â€“ Models participation bias effects (dropout, noisy updates) and fairness impact

## ğŸš€ How to Use

1. **Clone this repo**
   ```bash
   git clone https://github.com/your-username/FederatedCancerFL.git
   cd FederatedCancerFL
   ```

2. **Run notebooks**
   - `Synthetic Data.ipynb`: Generate and explore synthetic provincial datasets.  
   - `PathMNIST_federated_learning2.ipynb`: Train and evaluate federated models (with/without differential privacy).  

3. **Python scripts**
   - `DP.py`: Simulate privacy-preserving training and generate comparative performance metrics across privacy levels (Îµ).  
   - `equity_bias_simulation.py`: Reproduce fairnessâ€“performance trade-offs described in Section 4.3.

---

## ğŸ” Privacy

Federated learning experiments implement **Differentially Private SGD** with privacy budgets of Îµ â‰ˆ 1.0.  
All data used are synthetic or publicly available benchmarks (MedMNIST/PathMNIST).  
No identifiable or clinical data are included in this repository.

---

## ğŸ§­ Equity Simulation

`equity_bias_simulation.py` reproduces the fairnessâ€“performance trade-off discussed in Section 4.3 of the paper.  
It simulates dropout and noisy-update scenarios among provinces to quantify how unequal participation affects model accuracy and fairness.

---

## ğŸ“Š Dataset Description â€“ Synthetic Cancer Detection

This synthetic dataset emulates inter-provincial variation in cancer prevalence and patient demographics to study non-IID behavior in federated systems.

### ğŸ“ Files
- `ontario_cancer_data.csv`
- `alberta_cancer_data.csv`
- `quebec_cancer_data.csv`
- `synthetic_cancer_dataset.csv` â€“ Combined dataset (â‰ˆ 30,000 records)

### ğŸ“‹ Schema
| Column | Description |
|--------|-------------|
| `Province` | Province name (`Ontario`, `Alberta`, `Quebec`) |
| `Age` | Patient age (mean = 60 Â± 10) |
| `TumorSize` | Tumor size in cm (mean = 3.0 Â± 1.0) |
| `Biomarker` | Simulated biomarker level (mean = 100 Â± 25) |
| `Cancer` | Binary label: `1` = cancer, `0` = no cancer |

### ğŸ”„ Bias Simulation by Province
- **Ontario**: Balanced distribution (bias = 0)  
- **Alberta**: Lower prevalence (bias = âˆ’10)  
- **Quebec**: Higher prevalence (bias = +10)  

These bias factors are applied during data generation using a logistic probability model.

---

## ğŸ§ª Additional Dataset: PathMNIST Benchmark

We use the publicly available [PathMNIST](https://medmnist.com/) dataset from the **MedMNIST v2** collection to benchmark FL under real histopathology images.  
It contains 107,180 RGB (28Ã—28) images from 9 tissue classes of colorectal cancer.  

**Experiments include:**
- 3 non-IID clients (simulating provincial data)
- **ResNet-18** models with and without DP
- Evaluation metrics:
  - Accuracy
  - Macro-F1 Score
  - Privacy budget (Îµ â‰ˆ 1.0)

---

## âš–ï¸ Use Cases

This repository supports comparison of:
- Centralized vs. Federated Learning  
- Federated Learning + Differential Privacy  
- Fairness and performance trade-offs under non-IID conditions  
- Equity implications of participation bias across jurisdictions
- This is v1.0-rsos
- This repository provides supporting code and example simulations for the study
â€œBreaking Interprovincial Data Silos: How Federated Learning Can Unlock Canadaâ€™s Public Health Potential.â€
The code is intended to illustrate the proposed federated learning framework, governance instrumentation, and experimental design.
Due to stochastic training, synthetic data generation, and environment-specific dependencies, exact numerical reproduction of all reported results is not guaranteed.
---

## ğŸ“œ License
MIT License Â© 2025

---
